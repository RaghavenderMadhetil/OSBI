{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aad15188-67c7-4fcb-9529-2ad997a16ae5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 03_Run - ETL runner (delimiter detection + headers + parquet)\n",
    "# Paste this entire content into a Databricks notebook named \"03_Run\"\n",
    "# =========================\n",
    "\n",
    "import sys, importlib, re, traceback, json\n",
    "from pyspark.sql.functions import col, trim\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# ensure utils module importable from /FileStore\n",
    "if \"/dbfs/FileStore\" not in sys.path:\n",
    "    sys.path.insert(0, \"/dbfs/FileStore\")\n",
    "try:\n",
    "    import utils_etl\n",
    "    importlib.reload(utils_etl)\n",
    "    print(\"Imported utils_etl OK.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to import utils_etl - ensure /FileStore/utils_etl.py exists\")\n",
    "    raise\n",
    "\n",
    "# --- Widgets (ADF should pass these) ---\n",
    "dbutils.widgets.text(\"domain\", \"Finance\")\n",
    "dbutils.widgets.text(\"file_name\", \"\")            # e.g. Sales.Currency or Sales.Currency.csv\n",
    "dbutils.widgets.text(\"column_list\", \"\")          # JSON array OR CSV\n",
    "dbutils.widgets.text(\"year_column\", \"\")          # e.g. ModifiedDate (optional)\n",
    "dbutils.widgets.text(\"table_name\", \"\")           # folder name override (optional)\n",
    "\n",
    "dbutils.widgets.text(\"direct_account_key\", \"\")   # required or cluster must have access\n",
    "dbutils.widgets.text(\"BASE_RAW_PATH\", \"\")        # optional\n",
    "dbutils.widgets.text(\"BASE_BRONZE_PATH\", \"\")     # optional\n",
    "dbutils.widgets.text(\"include_layer\", \"false\")   # if you want /<layer> in path\n",
    "\n",
    "# read widgets\n",
    "DOMAIN = dbutils.widgets.get(\"domain\").strip()\n",
    "FILE_NAME_IN = dbutils.widgets.get(\"file_name\").strip()\n",
    "COLUMN_LIST_WIDGET = dbutils.widgets.get(\"column_list\").strip()\n",
    "YEAR_COLUMN_WIDGET = dbutils.widgets.get(\"year_column\").strip()\n",
    "TABLE_NAME_WIDGET = dbutils.widgets.get(\"table_name\").strip()\n",
    "DIRECT_KEY = dbutils.widgets.get(\"direct_account_key\").strip()\n",
    "BASE_RAW_WIDGET = dbutils.widgets.get(\"BASE_RAW_PATH\").strip()\n",
    "BASE_BRONZE_WIDGET = dbutils.widgets.get(\"BASE_BRONZE_PATH\").strip()\n",
    "INCLUDE_LAYER = dbutils.widgets.get(\"include_layer\").strip().lower() in (\"true\",\"1\",\"yes\",\"y\")\n",
    "\n",
    "# storage config\n",
    "STORAGE_ACCOUNT = \"scrgvkrmade\"\n",
    "RAW_CONTAINER = \"project\"\n",
    "BRONZE_CONTAINER = \"bronze\"\n",
    "\n",
    "# --- helper: detect delimiter by sampling head of file ---\n",
    "def detect_delimiter(file_path, sample_size=8192):\n",
    "    \"\"\"\n",
    "    Returns a best-guess delimiter from [',','|',';','\\t'] by counting occurrences in sample.\n",
    "    \"\"\"\n",
    "    text = None\n",
    "    try:\n",
    "        text = dbutils.fs.head(file_path, sample_size)\n",
    "    except Exception:\n",
    "        # if head fails (e.g. file not found) return default comma\n",
    "        return \",\"\n",
    "    # normalize CRLF\n",
    "    counts = {\n",
    "        \",\": text.count(\",\"),\n",
    "        \"|\": text.count(\"|\"),\n",
    "        \";\": text.count(\";\"),\n",
    "        \"\\t\": text.count(\"\\t\")\n",
    "    }\n",
    "    # choose delimiter with highest count (must have at least 1)\n",
    "    delim = max(counts, key=counts.get)\n",
    "    if counts[delim] == 0:\n",
    "        return \",\"\n",
    "    return delim\n",
    "\n",
    "# --- set storage key if passed (must do before abfss access) ---\n",
    "def set_storage_key(k):\n",
    "    if not k:\n",
    "        return\n",
    "    if (k.startswith('\"') and k.endswith('\"')) or (k.startswith(\"'\") and k.endswith(\"'\")):\n",
    "        k = k[1:-1]\n",
    "    k = k.strip()\n",
    "    if not re.fullmatch(r\"[A-Za-z0-9+/=]{20,300}\", k):\n",
    "        raise Exception(\"direct_account_key looks invalid; ensure you're passing raw account key (base64), not connection string\")\n",
    "    spark.conf.set(f\"fs.azure.account.key.{STORAGE_ACCOUNT}.dfs.core.windows.net\", k)\n",
    "    print(\"Set storage key for\", STORAGE_ACCOUNT)\n",
    "    # quick test\n",
    "    try:\n",
    "        display(dbutils.fs.ls(f\"abfss://{RAW_CONTAINER}@{STORAGE_ACCOUNT}.dfs.core.windows.net/\"))\n",
    "    except Exception as e:\n",
    "        print(\"Warning: test listing raw container failed (invalid key or container).\")\n",
    "        raise\n",
    "\n",
    "if DIRECT_KEY:\n",
    "    set_storage_key(DIRECT_KEY)\n",
    "else:\n",
    "    print(\"No direct_account_key provided; cluster auth must have permissions to read ABFS.\")\n",
    "\n",
    "# resolve base paths\n",
    "def task_or_widget(key, widget_name):\n",
    "    try:\n",
    "        v = dbutils.jobs.taskValues.get(taskKey=key, key=key)\n",
    "        if hasattr(v,\"value\"): return v.value\n",
    "        return v\n",
    "    except Exception:\n",
    "        return dbutils.widgets.get(widget_name).strip()\n",
    "\n",
    "BASE_RAW_TASK = task_or_widget(\"BASE_RAW_PATH\",\"BASE_RAW_PATH\")\n",
    "BASE_BRONZE_TASK = task_or_widget(\"BASE_BRONZE_PATH\",\"BASE_BRONZE_PATH\")\n",
    "\n",
    "if BASE_RAW_TASK:\n",
    "    BASE_RAW_PATH = BASE_RAW_TASK\n",
    "elif BASE_RAW_WIDGET:\n",
    "    BASE_RAW_PATH = BASE_RAW_WIDGET\n",
    "elif DIRECT_KEY:\n",
    "    BASE_RAW_PATH = f\"abfss://{RAW_CONTAINER}@{STORAGE_ACCOUNT}.dfs.core.windows.net\"\n",
    "else:\n",
    "    raise Exception(\"BASE_RAW_PATH not resolved. Provide direct_account_key or BASE_RAW_PATH widget or run 01_Config first.\")\n",
    "\n",
    "if BASE_BRONZE_TASK:\n",
    "    BASE_BRONZE_PATH = BASE_BRONZE_TASK\n",
    "elif BASE_BRONZE_WIDGET:\n",
    "    BASE_BRONZE_PATH = BASE_BRONZE_WIDGET\n",
    "elif DIRECT_KEY:\n",
    "    BASE_BRONZE_PATH = f\"abfss://{BRONZE_CONTAINER}@{STORAGE_ACCOUNT}.dfs.core.windows.net\"\n",
    "else:\n",
    "    raise Exception(\"BASE_BRONZE_PATH not resolved. Provide direct_account_key or BASE_BRONZE_PATH widget or run 01_Config first.\")\n",
    "\n",
    "print(\"BASE_RAW_PATH:\", BASE_RAW_PATH)\n",
    "print(\"BASE_BRONZE_PATH:\", BASE_BRONZE_PATH)\n",
    "\n",
    "# --- normalize file name and folder table name ---\n",
    "if not FILE_NAME_IN:\n",
    "    raise Exception(\"file_name widget required (e.g. Sales.Currency or Sales.Currency.csv)\")\n",
    "file_key = FILE_NAME_IN\n",
    "file_key_no_ext = file_key[:-4] if file_key.lower().endswith(\".csv\") else file_key\n",
    "folder_table_name = TABLE_NAME_WIDGET if TABLE_NAME_WIDGET else file_key_no_ext\n",
    "\n",
    "# --- parse column_list (accept JSON array or CSV) ---\n",
    "def parse_column_list(text):\n",
    "    txt = text.strip()\n",
    "    if not txt:\n",
    "        return []\n",
    "    txt = txt.replace('\"\"','\"')\n",
    "    if txt.startswith(\"[\") and txt.endswith(\"]\"):\n",
    "        try:\n",
    "            arr = json.loads(txt)\n",
    "            if isinstance(arr, list):\n",
    "                return [str(x).strip() for x in arr if x and str(x).strip()!=\"\"]\n",
    "        except Exception:\n",
    "            txt2 = txt.strip(\"[]\")\n",
    "            return [c.strip().strip('\"').strip(\"'\") for c in txt2.split(\",\") if c.strip()!='']\n",
    "    return [c.strip().strip('\"').strip(\"'\") for c in txt.split(\",\") if c.strip()!='']\n",
    "\n",
    "if COLUMN_LIST_WIDGET:\n",
    "    columns = parse_column_list(COLUMN_LIST_WIDGET)\n",
    "else:\n",
    "    raise Exception(\"column_list missing. Pass column_list from ADF Lookup (JSON array or CSV).\")\n",
    "\n",
    "if not columns:\n",
    "    raise Exception(\"Parsed columns list is empty. Provide valid column_list.\")\n",
    "\n",
    "# default year_hint to YEAR_COLUMN_WIDGET or ModifiedDate if present\n",
    "year_hint = YEAR_COLUMN_WIDGET if YEAR_COLUMN_WIDGET else None\n",
    "if not year_hint and any(c.lower()==\"modifieddate\" for c in columns):\n",
    "    year_hint = [c for c in columns if c.lower()==\"modifieddate\"][0]\n",
    "    print(\"Using ModifiedDate as year_hint\")\n",
    "\n",
    "# --- build raw path and detect delimiter ---\n",
    "raw_read_name = FILE_NAME_IN if FILE_NAME_IN and FILE_NAME_IN.strip()!=\"\" else file_key_no_ext + \".csv\"\n",
    "raw_path = BASE_RAW_PATH.rstrip(\"/\") + \"/\" + raw_read_name.lstrip(\"/\")\n",
    "print(\"Raw file path:\", raw_path)\n",
    "\n",
    "# detect delimiter by sampling first bytes\n",
    "detected_sep = detect_delimiter(raw_path, sample_size=8192)\n",
    "print(\"Detected delimiter:\", repr(detected_sep))\n",
    "\n",
    "# --- read CSV using detected delimiter and robust options ---\n",
    "try:\n",
    "    df_raw = (spark.read\n",
    "                .option(\"header\",\"false\")\n",
    "                .option(\"sep\", detected_sep)\n",
    "                .option(\"quote\", '\"')\n",
    "                .option(\"escape\", \"\\\\\")\n",
    "                .option(\"multiLine\", \"true\")\n",
    "                .option(\"inferSchema\", \"false\")\n",
    "                .csv(raw_path))\n",
    "    print(\"Raw row count:\", df_raw.count())\n",
    "    display(df_raw.limit(5))\n",
    "except Exception:\n",
    "    print(\"Failed to read CSV with detected delimiter; attempting fallback using comma.\")\n",
    "    try:\n",
    "        df_raw = (spark.read\n",
    "                    .option(\"header\",\"false\")\n",
    "                    .option(\"sep\", \",\")\n",
    "                    .option(\"quote\", '\"')\n",
    "                    .option(\"escape\", \"\\\\\")\n",
    "                    .option(\"multiLine\", \"true\")\n",
    "                    .option(\"inferSchema\", \"false\")\n",
    "                    .csv(raw_path))\n",
    "        print(\"Fallback read succeeded (comma). Row count:\", df_raw.count())\n",
    "        display(df_raw.limit(5))\n",
    "    except Exception:\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "# --- apply headers and trim whitespace ---\n",
    "df_named = utils_etl.add_headers(df_raw, columns)\n",
    "for c in df_named.columns:\n",
    "    df_named = df_named.withColumn(c, trim(col(c)))\n",
    "print(\"After applying headers sample:\")\n",
    "display(df_named.limit(5))\n",
    "\n",
    "# --- extract year and write parquet by year (folder structure: /<DOMAIN>/<table>/<year>) ---\n",
    "df_with_year, used_year = utils_etl.extract_year_column(df_named, year_hint)\n",
    "print(\"Year column used:\", used_year)\n",
    "print(\"Distinct years:\")\n",
    "display(df_with_year.select(\"_year\").distinct())\n",
    "\n",
    "if INCLUDE_LAYER:\n",
    "    bronze_base = BASE_BRONZE_PATH.rstrip(\"/\") + f\"/{DOMAIN}/{'Bronze'}\"\n",
    "else:\n",
    "    bronze_base = BASE_BRONZE_PATH.rstrip(\"/\") + f\"/{DOMAIN}\"\n",
    "\n",
    "print(\"Writing parquet to:\", bronze_base)\n",
    "utils_etl.write_parquet_by_year(df_with_year, bronze_base, folder_table_name, compression=\"snappy\", coalesce_out=True, write_mode=\"overwrite\")\n",
    "\n",
    "# --- confirm outputs ---\n",
    "years = [r[\"_year\"] for r in df_with_year.select(\"_year\").distinct().collect()]\n",
    "print(\"Outputs written for years:\", years)\n",
    "for y in years:\n",
    "    out_path = f\"{bronze_base.rstrip('/')}/{folder_table_name}/{y}\"\n",
    "    print(\"Listing:\", out_path)\n",
    "    try:\n",
    "        for f in dbutils.fs.ls(out_path):\n",
    "            print(\" -\", f.path)\n",
    "    except Exception as e:\n",
    "        print(\"Could not list:\", out_path, e)\n",
    "\n",
    "print(\"03_Run finished.\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_Run",
   "widgets": {
    "BASE_BRONZE_PATH": {
     "currentValue": "abfss://project@scrgvkrmade.dfs.core.windows.net/bronze/",
     "nuid": "460de8b5-d10c-4d07-a121-8507de6ad2ce",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "BASE_BRONZE_PATH",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "BASE_BRONZE_PATH",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "BASE_RAW_PATH": {
     "currentValue": "abfss://project@scrgvkrmade.dfs.core.windows.net/raw/",
     "nuid": "c5b1509c-316c-4dbd-a3c8-e851dd6c6a3a",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "BASE_RAW_PATH",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "BASE_RAW_PATH",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "column_list": {
     "currentValue": "[\"CurrencyCode\",\"Name\",\"ModifiedDate\"]",
     "nuid": "31d01d7d-6d35-4815-b1dc-9944585f536f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "column_list",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "column_list",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "direct_account_key": {
     "currentValue": "E4VB7pXWFXttUWbbSBPY35/Dvsw6Fs6XgIWLTj3lCS6v/jCEow9Uxs+r6Usobhenv14UdWEzb+R8+AStNyS0dg==",
     "nuid": "b4f418d5-49f2-4c1c-b12f-89ef7a162c8f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "direct_account_key",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "direct_account_key",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "domain": {
     "currentValue": "Finance",
     "nuid": "ebc9bb57-223f-4d30-be8f-f3fc976adac7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "Finance",
      "label": null,
      "name": "domain",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "Finance",
      "label": null,
      "name": "domain",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "file_name": {
     "currentValue": "Currency.csv",
     "nuid": "2b43b369-cf86-4316-b326-bc016fd60a1d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "file_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "file_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "include_layer": {
     "currentValue": "false",
     "nuid": "d302799f-44d3-4199-9705-0a922c6ac782",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "false",
      "label": null,
      "name": "include_layer",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "false",
      "label": null,
      "name": "include_layer",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "layer": {
     "currentValue": "Bronze",
     "nuid": "b0190891-ce6e-45e8-a2bd-b67432180470",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "Bronze",
      "label": null,
      "name": "layer",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "Bronze",
      "label": null,
      "name": "layer",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "table_name": {
     "currentValue": "Sales.Currency",
     "nuid": "8a4d02e3-de7d-48ba-835d-2e4939007185",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "table_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "table_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "year_column": {
     "currentValue": "ModifiedDate",
     "nuid": "d8ab2d10-6c24-49b9-bb28-167a8a48f95b",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "year_column",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "year_column",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
