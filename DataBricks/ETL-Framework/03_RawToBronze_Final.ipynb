{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9f5eab7-8247-4dde-bc8d-361acd61bc96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 03_Run - CSV -> Bronze\n",
    "# Beginner friendly - no external utils required\n",
    "# =========================\n",
    "\n",
    "import json, uuid, datetime, traceback\n",
    "from pyspark.sql.functions import col, trim, current_timestamp, current_date, lit, to_timestamp, year\n",
    "\n",
    "# Widgets\n",
    "dbutils.widgets.text(\"domain\", \"\")\n",
    "dbutils.widgets.text(\"file_name\", \"\")         # Sales.Currency or Sales.Currency.csv\n",
    "dbutils.widgets.text(\"column_list\", \"\")       # JSON array or CSV of headers\n",
    "dbutils.widgets.text(\"year_column\", \"\")       # optional hint, e.g. ModifiedDate\n",
    "dbutils.widgets.text(\"table_name\", \"\")        # optional folder name override\n",
    "dbutils.widgets.text(\"batch_name\", \"\")        # optional\n",
    "dbutils.widgets.text(\"direct_account_key\", \"\")# optional storage key\n",
    "dbutils.widgets.text(\"BASE_RAW_PATH\", \"\")     # e.g. abfss://project@acct.dfs.core.windows.net\n",
    "dbutils.widgets.text(\"BASE_BRONZE_PATH\", \"\")  # e.g. abfss://bronze@acct.dfs.core.windows.net\n",
    "dbutils.widgets.text(\"include_layer\", \"false\")# true to include /Bronze\n",
    "\n",
    "# Read widgets\n",
    "DOMAIN = dbutils.widgets.get(\"domain\").strip()\n",
    "FILE_NAME_IN = dbutils.widgets.get(\"file_name\").strip()\n",
    "COLUMN_LIST_WIDGET = dbutils.widgets.get(\"column_list\").strip()\n",
    "YEAR_COLUMN_WIDGET = dbutils.widgets.get(\"year_column\").strip()\n",
    "TABLE_NAME_WIDGET = dbutils.widgets.get(\"table_name\").strip()\n",
    "BATCH_NAME_WIDGET = dbutils.widgets.get(\"batch_name\").strip()\n",
    "DIRECT_KEY = dbutils.widgets.get(\"direct_account_key\").strip()\n",
    "BASE_RAW_WIDGET = dbutils.widgets.get(\"BASE_RAW_PATH\").strip()\n",
    "BASE_BRONZE_WIDGET = dbutils.widgets.get(\"BASE_BRONZE_PATH\").strip()\n",
    "INCLUDE_LAYER = dbutils.widgets.get(\"include_layer\").strip().lower() in (\"true\",\"1\",\"yes\",\"y\")\n",
    "\n",
    "# Safe defaults / simple validation\n",
    "if not FILE_NAME_IN:\n",
    "    raise RuntimeError(\"Provide file_name widget (e.g. Sales.Currency or Sales.Currency.csv)\")\n",
    "\n",
    "# Configure storage key if passed\n",
    "acct = None\n",
    "if DIRECT_KEY:\n",
    "    key = DIRECT_KEY.strip().strip('\"').strip(\"'\")\n",
    "    if BASE_RAW_WIDGET and \"@\" in BASE_RAW_WIDGET:\n",
    "        acct = BASE_RAW_WIDGET.split(\"@\",1)[1].split(\".\")[0]\n",
    "    elif BASE_BRONZE_WIDGET and \"@\" in BASE_BRONZE_WIDGET:\n",
    "        acct = BASE_BRONZE_WIDGET.split(\"@\",1)[1].split(\".\")[0]\n",
    "    if not acct:\n",
    "        acct = \"scrgvkrmade\"\n",
    "    spark.conf.set(f\"fs.azure.account.key.{acct}.dfs.core.windows.net\", key)\n",
    "    print(\"Configured storage key for account:\", acct)\n",
    "else:\n",
    "    print(\"No storage key passed; relying on cluster identity or mounts.\")\n",
    "\n",
    "# Resolve raw / bronze base paths\n",
    "if BASE_RAW_WIDGET:\n",
    "    BASE_RAW_PATH = BASE_RAW_WIDGET.rstrip(\"/\")\n",
    "else:\n",
    "    BASE_RAW_PATH = f\"abfss://project@{acct}.dfs.core.windows.net\"\n",
    "\n",
    "if BASE_BRONZE_WIDGET:\n",
    "    BASE_BRONZE_PATH = BASE_BRONZE_WIDGET.rstrip(\"/\")\n",
    "else:\n",
    "    BASE_BRONZE_PATH = f\"abfss://bronze@{acct}.dfs.core.windows.net\"\n",
    "\n",
    "print(\"BASE_RAW_PATH:\", BASE_RAW_PATH)\n",
    "print(\"BASE_BRONZE_PATH:\", BASE_BRONZE_PATH)\n",
    "\n",
    "# Build file & folder names\n",
    "raw_filename = FILE_NAME_IN if FILE_NAME_IN.lower().endswith(\".csv\") else FILE_NAME_IN + \".csv\"\n",
    "file_key_no_ext = raw_filename[:-4]\n",
    "folder_table_name = TABLE_NAME_WIDGET if TABLE_NAME_WIDGET else file_key_no_ext\n",
    "raw_path = BASE_RAW_PATH + \"/\" + raw_filename\n",
    "print(\"Raw file path:\", raw_path)\n",
    "\n",
    "# Detect delimiter by sampling file head\n",
    "sep = \",\"\n",
    "try:\n",
    "    sample = dbutils.fs.head(raw_path, 8192)\n",
    "    counts = {\",\": sample.count(\",\"), \"|\": sample.count(\"|\"), \";\": sample.count(\";\"), \"\\t\": sample.count(\"\\t\")}\n",
    "    sep = max(counts, key=counts.get)\n",
    "    if counts[sep] == 0:\n",
    "        sep = \",\"\n",
    "except Exception as e:\n",
    "    print(\"Could not sample file; defaulting to comma. Error:\", e)\n",
    "    sep = \",\"\n",
    "print(\"Detected delimiter:\", repr(sep))\n",
    "\n",
    "# Read CSV robustly (no schema inference)\n",
    "try:\n",
    "    df_raw = (spark.read\n",
    "                .option(\"header\",\"false\")\n",
    "                .option(\"sep\", sep)\n",
    "                .option(\"quote\", '\"')\n",
    "                .option(\"escape\", \"\\\\\")\n",
    "                .option(\"multiLine\", \"true\")\n",
    "                .option(\"inferSchema\", \"false\")\n",
    "                .csv(raw_path))\n",
    "    print(\"Raw rows:\", df_raw.count())\n",
    "    display(df_raw.limit(5))\n",
    "except Exception:\n",
    "    print(\"Initial read failed; falling back to comma delimiter.\")\n",
    "    df_raw = (spark.read\n",
    "                .option(\"header\",\"false\")\n",
    "                .option(\"sep\", \",\")\n",
    "                .option(\"quote\", '\"')\n",
    "                .option(\"escape\", \"\\\\\")\n",
    "                .option(\"multiLine\", \"true\")\n",
    "                .option(\"inferSchema\", \"false\")\n",
    "                .csv(raw_path))\n",
    "    print(\"Fallback rows:\", df_raw.count())\n",
    "    display(df_raw.limit(5))\n",
    "\n",
    "# Parse column_list widget to headers\n",
    "cols = []\n",
    "if COLUMN_LIST_WIDGET:\n",
    "    txt = COLUMN_LIST_WIDGET.strip()\n",
    "    try:\n",
    "        parsed = json.loads(txt)\n",
    "        if isinstance(parsed, list) and parsed:\n",
    "            cols = [str(x).strip() for x in parsed]\n",
    "        else:\n",
    "            cols = [c.strip() for c in txt.split(\",\") if c.strip()]\n",
    "    except Exception:\n",
    "        cols = [c.strip() for c in txt.split(\",\") if c.strip()]\n",
    "\n",
    "if not cols:\n",
    "    raise RuntimeError(\"column_list parsed empty. Provide valid column_list.\")\n",
    "\n",
    "print(\"Applying headers:\", cols)\n",
    "\n",
    "# Apply headers to df_raw (rename first N columns)\n",
    "for i, raw_col in enumerate(df_raw.columns):\n",
    "    if i < len(cols):\n",
    "        df_raw = df_raw.withColumnRenamed(raw_col, cols[i])\n",
    "\n",
    "df_named = df_raw\n",
    "# Trim all string columns\n",
    "for c,t in df_named.dtypes:\n",
    "    if t == \"string\":\n",
    "        df_named = df_named.withColumn(c, trim(col(c)))\n",
    "\n",
    "display(df_named.limit(5))\n",
    "\n",
    "# Safe year extraction: only try to parse values that look like dates\n",
    "year_col_used = None\n",
    "if YEAR_COLUMN_WIDGET and YEAR_COLUMN_WIDGET in df_named.columns:\n",
    "    year_col_used = YEAR_COLUMN_WIDGET\n",
    "elif \"ModifiedDate\" in df_named.columns:\n",
    "    year_col_used = \"ModifiedDate\"\n",
    "\n",
    "if year_col_used:\n",
    "    print(\"Trying to use year column:\", year_col_used)\n",
    "    from pyspark.sql.functions import when\n",
    "    df_named = df_named.withColumn(\n",
    "        year_col_used,\n",
    "        when(col(year_col_used).rlike(r'^\\s*\\d{4}[-/]\\d{1,2}[-/]\\d{1,2}'), col(year_col_used)).otherwise(None)\n",
    "    )\n",
    "    df_named = df_named.withColumn(year_col_used, to_timestamp(col(year_col_used)))\n",
    "    df_named = df_named.withColumn(\"_year\", when(col(year_col_used).isNotNull(), year(col(year_col_used))).otherwise(lit(datetime.datetime.utcnow().year)))\n",
    "else:\n",
    "    df_named = df_named.withColumn(\"_year\", lit(datetime.datetime.utcnow().year))\n",
    "\n",
    "print(\"Year column used:\", year_col_used)\n",
    "display(df_named.select(\"_year\").distinct())\n",
    "\n",
    "# Add audit columns\n",
    "_run_id = str(uuid.uuid4())\n",
    "_job_id = \"\"  # optional best-effort\n",
    "df_audited = (df_named\n",
    "                .withColumn(\"_ingestion_ts\", current_timestamp())\n",
    "                .withColumn(\"_ingestion_date\", current_date())\n",
    "                .withColumn(\"_source_file\", lit(raw_filename))\n",
    "                .withColumn(\"_source_path\", lit(raw_path))\n",
    "                .withColumn(\"_job_id\", lit(_job_id))\n",
    "                .withColumn(\"_run_id\", lit(_run_id))\n",
    "                .withColumn(\"_batch_id\", lit(BATCH_NAME_WIDGET if BATCH_NAME_WIDGET else \"\")))\n",
    "\n",
    "display(df_audited.limit(5))\n",
    "\n",
    "# Build bronze base path and write parquet (partition by _year)\n",
    "if INCLUDE_LAYER:\n",
    "    bronze_base = BASE_BRONZE_PATH.rstrip(\"/\") + f\"/{DOMAIN}/Bronze\"\n",
    "else:\n",
    "    bronze_base = BASE_BRONZE_PATH.rstrip(\"/\") + f\"/{DOMAIN}\"\n",
    "\n",
    "out_path = f\"{bronze_base}/{folder_table_name}\"\n",
    "print(\"Writing parquet to:\", out_path)\n",
    "\n",
    "(df_audited\n",
    "   .write\n",
    "   .mode(\"overwrite\")\n",
    "   .option(\"compression\",\"snappy\")\n",
    "   .partitionBy(\"_year\")\n",
    "   .parquet(out_path))\n",
    "\n",
    "print(\"Write complete.\")\n",
    "\n",
    "# Validate written files\n",
    "years = [r[\"_year\"] for r in df_audited.select(\"_year\").distinct().collect()]\n",
    "print(\"Outputs written for years:\", years)\n",
    "for y in years:\n",
    "    p = f\"{out_path}/_year={y}\"\n",
    "    print(\"Listing:\", p)\n",
    "    try:\n",
    "        for f in dbutils.fs.ls(p):\n",
    "            print(\" -\", f.path)\n",
    "    except Exception as e:\n",
    "        print(\"Could not list:\", p, e)\n",
    "\n",
    "print(\"03_Run finished.\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_RawToBronze_Final",
   "widgets": {
    "BASE_BRONZE_PATH": {
     "currentValue": "abfss://project@scrgvkrmade.dfs.core.windows.net/bronze/",
     "nuid": "4bcfa94e-ba1a-48ed-a440-0057a6d82685",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "BASE_BRONZE_PATH",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "BASE_BRONZE_PATH",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "BASE_RAW_PATH": {
     "currentValue": "abfss://project@scrgvkrmade.dfs.core.windows.net/raw/",
     "nuid": "5ecdbd08-772e-4b0d-b0d0-fc3fb97b0f4e",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "BASE_RAW_PATH",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "BASE_RAW_PATH",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "batch_name": {
     "currentValue": "RS_Raw_06",
     "nuid": "ed644717-80a0-4f79-9640-c337da09aa6f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "batch_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "batch_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "column_list": {
     "currentValue": "[\"CustomerID\", \"PersonID\", \"StoreID\", \"TerritoryID\", \"AccountNumber\", \"rowguid\", \"ModifiedDate\"]",
     "nuid": "4306b917-2459-4d93-885a-5de26e00b183",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "column_list",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "column_list",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "direct_account_key": {
     "currentValue": "E4VB7pXWFXttUWbbSBPY35/Dvsw6Fs6XgIWLTj3lCS6v/jCEow9Uxs+r6Usobhenv14UdWEzb+R8+AStNyS0dg==",
     "nuid": "f5846ce8-c878-4502-943c-943c577fd64d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "direct_account_key",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "direct_account_key",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "domain": {
     "currentValue": "ResellerSales",
     "nuid": "7c0c8e68-d6bc-4b99-918c-8c602fe8db41",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "domain",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "domain",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "file_name": {
     "currentValue": "Customer.csv",
     "nuid": "26af4b5f-dda2-4ed3-ae7f-f38331faea45",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "file_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "file_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "include_layer": {
     "currentValue": "false",
     "nuid": "77b4e548-10aa-44a8-a076-a19ae81721f4",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "false",
      "label": null,
      "name": "include_layer",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "false",
      "label": null,
      "name": "include_layer",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "table_name": {
     "currentValue": "Sales.Customer",
     "nuid": "b240a527-bb12-4981-b4e0-6f879dcb5543",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "table_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "table_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "year_column": {
     "currentValue": "ModifiedDate",
     "nuid": "8b9d7343-5d7b-4c98-8f13-e31bc31c7490",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "year_column",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "year_column",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
